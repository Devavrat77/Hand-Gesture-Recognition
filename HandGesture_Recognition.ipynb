{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56583c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cc123a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import uuid\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "935f9880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.activation import sigmoid , relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c94633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "642a5e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " # Assuming the number of columns in your data is the input dimension\n",
    "\n",
    "# You can also load the corresponding target labels if needed.\n",
    "# y_train = df['target_column_name'].values\n",
    "# y_val = df_val['target_column_name'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c96dc109",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Gestures/train.csv\")\n",
    "\n",
    "test= pd.read_csv(\"Gestures/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f89d318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         1         2         3         4         5         6  \\\n",
      "0     0.700815  0.817016  0.913290  0.965638  1.009962  0.900352  0.936875   \n",
      "1     0.259255  0.373427  0.478504  0.523586  0.569484  0.460720  0.506533   \n",
      "2     0.268086  0.410477  0.535903  0.623081  0.697295  0.468710  0.538524   \n",
      "3     0.280768  0.392727  0.497226  0.544058  0.585926  0.476203  0.523252   \n",
      "4     0.569508  0.432314  0.388524  0.372655  0.349282  0.447670  0.431069   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1461  0.645774  0.601368  0.524931  0.490376  0.482107  0.460943  0.289306   \n",
      "1462  0.901229  0.876578  0.815571  0.772957  0.785174  0.665086  0.527039   \n",
      "1463  0.635058  0.710582  0.728793  0.706619  0.727111  0.528210  0.537311   \n",
      "1464  0.774853  0.725720  0.673570  0.638181  0.646785  0.621173  0.443561   \n",
      "1465  0.899673  0.877171  0.820041  0.778414  0.786567  0.679244  0.548030   \n",
      "\n",
      "             7         8         9  ...        53        54        55  \\\n",
      "0     0.952500  0.964836  0.857783  ...  0.004432 -0.012543  0.028345   \n",
      "1     0.523856  0.536200  0.402161  ... -0.008052 -0.023995  0.020295   \n",
      "2     0.574980  0.598539  0.392142  ... -0.040363 -0.055135 -0.016060   \n",
      "3     0.542614  0.555386  0.418555  ... -0.017917 -0.033483  0.011587   \n",
      "4     0.407376  0.394215  0.487516  ...  0.308639  0.341260  0.099824   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1461  0.342266  0.401151  0.462368  ... -0.124252 -0.117598 -0.119434   \n",
      "1462  0.577918  0.642515  0.630081  ... -0.056133 -0.055253 -0.058693   \n",
      "1463  0.604911  0.614507  0.438838  ... -0.092372 -0.086797 -0.030581   \n",
      "1464  0.456498  0.497165  0.619006  ... -0.089633 -0.073404 -0.140009   \n",
      "1465  0.597325  0.653414  0.651137  ... -0.075313 -0.073173 -0.069360   \n",
      "\n",
      "            56        57        58        59        60        61        62  \n",
      "0     0.015023 -0.004050 -0.017267  0.019353  0.004624 -0.005304 -0.011818  \n",
      "1     0.007773 -0.011616 -0.025879  0.015776 -0.000782 -0.012971 -0.020643  \n",
      "2    -0.036245 -0.060303 -0.078554 -0.025339 -0.053600 -0.072802 -0.085374  \n",
      "3    -0.001847 -0.020119 -0.033848  0.006572 -0.010908 -0.023009 -0.030693  \n",
      "4     0.144717  0.176742  0.197169  0.010957  0.020910  0.033310  0.045591  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1461 -0.150363 -0.120032 -0.099904 -0.136005 -0.159926 -0.139259 -0.120537  \n",
      "1462 -0.063186 -0.040823 -0.028633 -0.071873 -0.066400 -0.039265 -0.017750  \n",
      "1463 -0.083649 -0.065597 -0.044935 -0.030551 -0.060243 -0.045884 -0.027467  \n",
      "1464 -0.141532 -0.095284 -0.076702 -0.168683 -0.172507 -0.147799 -0.135531  \n",
      "1465 -0.083152 -0.064601 -0.053104 -0.079144 -0.084342 -0.064164 -0.046416  \n",
      "\n",
      "[1466 rows x 63 columns]\n",
      "0           palm\n",
      "1           palm\n",
      "2           palm\n",
      "3           palm\n",
      "4           palm\n",
      "          ...   \n",
      "1461    thumbsup\n",
      "1462    thumbsup\n",
      "1463    thumbsup\n",
      "1464    thumbsup\n",
      "1465    thumbsup\n",
      "Name: 63, Length: 1466, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_train = train.iloc[:,:-1]\n",
    "print(X_train)\n",
    "Y_train = train.iloc[:,-1]\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cf0407a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6  \\\n",
      "0    0.674419  0.515458  0.399471  0.344193  0.280377  0.481600  0.443068   \n",
      "1    0.115811  0.268684  0.402639  0.489739  0.558926  0.351709  0.421467   \n",
      "2    0.712132  0.568713  0.493371  0.473895  0.447229  0.574367  0.541534   \n",
      "3    0.107500  0.253071  0.374162  0.429010  0.491236  0.318932  0.335627   \n",
      "4    0.445751  0.600835  0.738686  0.850495  0.938802  0.700696  0.815737   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "363  0.546542  0.533328  0.490241  0.441491  0.434898  0.316872  0.267787   \n",
      "364  0.263741  0.316998  0.319499  0.301107  0.325338  0.183550  0.116358   \n",
      "365  0.905564  0.880058  0.825066  0.778057  0.784253  0.678073  0.561832   \n",
      "366  0.230746  0.309734  0.345654  0.340329  0.370677  0.225770  0.216449   \n",
      "367  0.777513  0.751938  0.706624  0.684768  0.690116  0.626440  0.472431   \n",
      "\n",
      "            7         8         9  ...        53        54        55  \\\n",
      "0    0.423565  0.408941  0.564372  ...  0.061597  0.052206  0.036532   \n",
      "1    0.456421  0.477849  0.274332  ...  0.145877  0.162311  0.081280   \n",
      "2    0.512778  0.489063  0.657261  ... -0.124834 -0.155725 -0.062923   \n",
      "3    0.329211  0.319145  0.236970  ... -0.050411 -0.075825 -0.001069   \n",
      "4    0.894031  0.960161  0.606123  ... -0.276527 -0.313855 -0.168275   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "363  0.313500  0.356943  0.272536  ... -0.015170 -0.021854 -0.033647   \n",
      "364  0.177957  0.226470  0.128635  ... -0.091306 -0.077394 -0.024369   \n",
      "365  0.610940  0.662277  0.649478  ... -0.031816 -0.027943 -0.068327   \n",
      "366  0.247687  0.262786  0.159177  ... -0.079378 -0.071374 -0.021238   \n",
      "367  0.508551  0.563041  0.615183  ... -0.105533 -0.102893 -0.106965   \n",
      "\n",
      "           56        57        58        59        60        61        62  \n",
      "0    0.040143  0.032374  0.022547  0.014618  0.011814  0.011836  0.009658  \n",
      "1    0.114852  0.129806  0.137399  0.075981  0.085712  0.089295  0.095801  \n",
      "2   -0.107674 -0.144878 -0.170170 -0.089655 -0.130852 -0.152818 -0.167281  \n",
      "3   -0.028786 -0.056109 -0.076393 -0.012334 -0.043801 -0.061181 -0.072865  \n",
      "4   -0.239366 -0.289593 -0.327068 -0.184960 -0.260269 -0.303574 -0.332755  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "363 -0.015713 -0.007548 -0.010599 -0.036491 -0.021660 -0.006147  0.005254  \n",
      "364 -0.085800 -0.065302 -0.034302 -0.030710 -0.066582 -0.053489 -0.032019  \n",
      "365 -0.056158 -0.030814 -0.023150 -0.077991 -0.066935 -0.040990 -0.023119  \n",
      "366 -0.074639 -0.065497 -0.047460 -0.024452 -0.057374 -0.053363 -0.040902  \n",
      "367 -0.129737 -0.109667 -0.098213 -0.120999 -0.141754 -0.129729 -0.118820  \n",
      "\n",
      "[368 rows x 63 columns]\n",
      "0          palm\n",
      "1          palm\n",
      "2          palm\n",
      "3          palm\n",
      "4          palm\n",
      "         ...   \n",
      "363    thumbsup\n",
      "364    thumbsup\n",
      "365    thumbsup\n",
      "366    thumbsup\n",
      "367    thumbsup\n",
      "Name: 63, Length: 368, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_test = test.iloc[:,:-1]\n",
    "print(X_test)\n",
    "Y_test = test.iloc[:,-1]\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "567bdc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the labels in Y_train\n",
    "Y_train = label_encoder.fit_transform(Y_train)\n",
    "Y_test = label_encoder.fit_transform(Y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Example encoded labels\n",
    "# encoded_labels = [2, 0, 1, 2, 1, 0]\n",
    "\n",
    "# # Create a LabelEncoder and fit it to the original labels\n",
    "# label_encoder = LabelEncoder()\n",
    "# original_labels = [\"cat\", \"dog\", \"fish\"]\n",
    "\n",
    "# label_encoder.fit(original_labels)\n",
    "\n",
    "# # Decode the encoded labels\n",
    "# decoded_labels = label_encoder.inverse_transform(encoded_labels)\n",
    "# print(decoded_labels)  # Output: ['fish' 'cat' 'dog' 'fish' 'dog' 'cat']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ed74ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50c169a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     Dense(units= 10, activation=\"relu\"),\n",
    "#     Dense(units = 30, activation=\"relu\"),\n",
    "#     Dense(units = 40, activation=\"relu\"),\n",
    "#     Dense(units = 1, activation=\"sigmoid\")\n",
    "# ])\n",
    "# from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(units=128, activation=\"relu\"),  # Adjust 'input_shape'\n",
    "    Dropout(0.5),\n",
    "    Dense(units=64, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=32, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=1, activation=\"sigmoid\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39636208",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "46/46 [==============================] - 5s 12ms/step - loss: 0.5790 - accuracy: 0.7080\n",
      "Epoch 2/15\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.2045 - accuracy: 0.9461\n",
      "Epoch 3/15\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0625 - accuracy: 0.9877\n",
      "Epoch 4/15\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0312 - accuracy: 0.9932\n",
      "Epoch 5/15\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0198 - accuracy: 0.9973\n",
      "Epoch 6/15\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0136 - accuracy: 0.9980\n",
      "Epoch 7/15\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0112 - accuracy: 0.9973\n",
      "Epoch 8/15\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0092 - accuracy: 0.9986\n",
      "Epoch 9/15\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0066 - accuracy: 0.9986\n",
      "Epoch 10/15\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0069 - accuracy: 0.9986\n",
      "Epoch 12/15\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 0.9993\n",
      "Epoch 14/15\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 0.9993\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.0542e-06 - accuracy: 1.0000\n",
      "Test Loss: 4.054224518768024e-06, Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train, epochs=15, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd356130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b977ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "706497f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gestures list\n",
    "Gestures = [\"palm\",\"thumbsup\",\"Gesture3\",\"Gesture4\",\"Gesture5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecb6bbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 178ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "['palm']\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "['palm']\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "['palm']\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "['palm']\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "['palm']\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "['palm']\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "['palm']\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "['palm']\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "['palm']\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "['palm']\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "['palm']\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "['palm']\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "['palm']\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "['thumbsup']\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "['palm']\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "['palm']\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "['palm']\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "['palm']\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "['palm']\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "['palm']\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "['palm']\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "['palm']\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(min_detection_confidence=0.8 , min_tracking_confidence = 0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        res , frame = cap.read()\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "#         print(results)\n",
    "\n",
    "        \n",
    "#         if results.multi_hand_landmarks:\n",
    "#             for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "#                 mp_drawing.draw_landmarks(image , hand , mp_hands.HAND_CONNECTIONS)\n",
    "#             cv2.imwrite(os.path.join(\"Gestures\",\"{}.jpg\".format(uuid.uuid1())),image)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                mp_drawing.draw_landmarks(image , hand , mp_hands.HAND_CONNECTIONS)\n",
    "            a = results.multi_hand_landmarks\n",
    "            xtr = np.array([a[0].landmark[i].x for i in range(21)] +\n",
    "               [a[0].landmark[i].y for i in range(21)] +\n",
    "               [a[0].landmark[i].z for i in range(21)])\n",
    "\n",
    "            xtr = xtr.flatten()# Flatten the array to create a 1D array if needed\n",
    "            xtr = xtr.reshape(1,63)\n",
    "            if xtr.shape == (1,63):\n",
    "#                 print(xtr.shape)\n",
    "                gesture = model.predict(xtr)\n",
    "                if gesture<=0.5:\n",
    "                    gesture=0\n",
    "                else :\n",
    "                    gesture = 1\n",
    "\n",
    "#                 # Example encoded labels\n",
    "#                 encoded_labels = [0,1]\n",
    "\n",
    "#                 # Create a LabelEncoder and fit it to the original labels\n",
    "#                 label_encoder = LabelEncoder()\n",
    "#                 original_labels = [\"palm\",\"thumbsup\"]\n",
    "#                 label_encoder.fit(original_labels)\n",
    "                decoded_labels = label_encoder.inverse_transform([gesture])\n",
    "                print(decoded_labels)  # Output: ['', '' , '']\n",
    "\n",
    "#                 print(gesture)\n",
    "#             if gesture in Gestures:\n",
    "                #perform action based on gesture\n",
    "            \n",
    "        \n",
    "        cv2.imshow(\"Hand Tracking \",image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xff == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e81cccae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({(0, 1),\n",
       "           (0, 5),\n",
       "           (0, 17),\n",
       "           (1, 2),\n",
       "           (2, 3),\n",
       "           (3, 4),\n",
       "           (5, 6),\n",
       "           (5, 9),\n",
       "           (6, 7),\n",
       "           (7, 8),\n",
       "           (9, 10),\n",
       "           (9, 13),\n",
       "           (10, 11),\n",
       "           (11, 12),\n",
       "           (13, 14),\n",
       "           (13, 17),\n",
       "           (14, 15),\n",
       "           (15, 16),\n",
       "           (17, 18),\n",
       "           (18, 19),\n",
       "           (19, 20)})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_hands.HAND_CONNECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c8c7cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cv2.imwrite(os.path.join(\"Gestures\",\"Gesture_{i}\",\"{}.jpg\".format(uuid.uuid1())),image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d5a28d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=results.multi_hand_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2f6eb7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Programming\\projects\\hand recognition\\HandGesture_Recognition.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Programming/projects/hand%20recognition/HandGesture_Recognition.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m xtr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([a[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mlandmark[i]\u001b[39m.\u001b[39mx \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m21\u001b[39m)] \u001b[39m+\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programming/projects/hand%20recognition/HandGesture_Recognition.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                [a[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mlandmark[i]\u001b[39m.\u001b[39my \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m21\u001b[39m)] \u001b[39m+\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programming/projects/hand%20recognition/HandGesture_Recognition.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                [a[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mlandmark[i]\u001b[39m.\u001b[39mz \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m21\u001b[39m)])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programming/projects/hand%20recognition/HandGesture_Recognition.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m xtr1 \u001b[39m=\u001b[39m xtr\u001b[39m.\u001b[39mflatten() \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programming/projects/hand%20recognition/HandGesture_Recognition.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m xtr1\n",
      "\u001b[1;32md:\\Programming\\projects\\hand recognition\\HandGesture_Recognition.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Programming/projects/hand%20recognition/HandGesture_Recognition.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m xtr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([a[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39mlandmark[i]\u001b[39m.\u001b[39mx \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m21\u001b[39m)] \u001b[39m+\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programming/projects/hand%20recognition/HandGesture_Recognition.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                [a[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mlandmark[i]\u001b[39m.\u001b[39my \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m21\u001b[39m)] \u001b[39m+\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programming/projects/hand%20recognition/HandGesture_Recognition.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                [a[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mlandmark[i]\u001b[39m.\u001b[39mz \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m21\u001b[39m)])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programming/projects/hand%20recognition/HandGesture_Recognition.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m xtr1 \u001b[39m=\u001b[39m xtr\u001b[39m.\u001b[39mflatten() \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programming/projects/hand%20recognition/HandGesture_Recognition.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m xtr1\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "xtr = np.array([a[0].landmark[i].x for i in range(21)] +\n",
    "               [a[0].landmark[i].y for i in range(21)] +\n",
    "               [a[0].landmark[i].z for i in range(21)])\n",
    "\n",
    "xtr1 = xtr.flatten() \n",
    "xtr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d2d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr= np.array([i for i in range(21):\n",
    "               a[0].landmark[i].x ,a[0].landmark[i].y,a[0].landmark[i].z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b039f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr =[]\n",
    "for i in range(21):\n",
    "    xtr.append(a[0].landmark[i].x)\n",
    "    xtr.append(a[0].landmark[i].y)\n",
    "    xtr.append(a[0].landmark[i].z)\n",
    "xtr=np.array(xtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf4a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(xtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e59335",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr==xtr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83934746",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0].landmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8287a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0].landmark[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640e4ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "type(a[0].landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64385da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e61159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df190f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c662b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy\n",
    "    \n",
    ")\n",
    "model.fit(\n",
    "    xt,yt,epochs = 10\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce47346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow) new",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
