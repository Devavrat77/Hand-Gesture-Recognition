{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c7b4c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import uuid\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e512db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "494310c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(\"Gestures\\Gesture_1\\gesture.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "856679ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(min_detection_confidence=0.8 , min_tracking_confidence = 0.5) as hands:\n",
    "    count = 0\n",
    "    while cap.isOpened() and count!= 1000:\n",
    "        res , frame = cap.read()\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image , cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "                \n",
    "                cv2.imwrite(os.path.join(f\"Gestures\\Gesture_2\\Gesture_2\",\"{}.jpg\".format(f'image_{count}')),frame)\n",
    "                count+=1\n",
    "                            \n",
    "#                 if count%1000:\n",
    "#                     i+=1        \n",
    "#                 cv2.imwrite(os.path.join(f\"Gestures\\Gesture_{i}\",\"{}.jpg\".format(uuid.uuid1())),xtr)\n",
    "                \n",
    "            \n",
    "#         if results.multi_hand_landmarks:\n",
    "#             xtr = np.array([a[0].landmark[i].x for i in range(21)] +\n",
    "#                [a[0].landmark[i].y for i in range(21)] +\n",
    "#                [a[0].landmark[i].z for i in range(21)])\n",
    "\n",
    "#             xtr = xtr.flatten()  # Flatten the array to create a 1D array if needed\n",
    "\n",
    "#             gesture = model.predict(xtr)\n",
    "#             if gesture in Gestures:\n",
    "#                 #perform action based on gesture\n",
    "            \n",
    "        \n",
    "        cv2.imshow(\"Hand Tracking \",image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xff == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ced103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 94  74  75]\n",
      "  [ 96  75  76]\n",
      "  [ 99  77  78]\n",
      "  ...\n",
      "  [170 143 146]\n",
      "  [172 146 147]\n",
      "  [175 148 149]]\n",
      "\n",
      " [[ 97  77  79]\n",
      "  [ 97  76  78]\n",
      "  [ 98  76  78]\n",
      "  ...\n",
      "  [169 141 147]\n",
      "  [172 145 149]\n",
      "  [173 146 150]]\n",
      "\n",
      " [[ 98  79  83]\n",
      "  [ 97  77  81]\n",
      "  [ 95  75  79]\n",
      "  ...\n",
      "  [163 135 144]\n",
      "  [170 142 150]\n",
      "  [172 144 152]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[167 152 126]\n",
      "  [167 152 128]\n",
      "  [169 154 131]\n",
      "  ...\n",
      "  [ 80  63  84]\n",
      "  [ 81  64  85]\n",
      "  [ 84  67  87]]\n",
      "\n",
      " [[174 157 129]\n",
      "  [171 155 128]\n",
      "  [172 157 132]\n",
      "  ...\n",
      "  [ 80  63  85]\n",
      "  [ 80  63  84]\n",
      "  [ 83  65  86]]\n",
      "\n",
      " [[182 164 135]\n",
      "  [183 166 139]\n",
      "  [176 160 135]\n",
      "  ...\n",
      "  [ 84  66  88]\n",
      "  [ 84  67  87]\n",
      "  [ 85  68  89]]]\n"
     ]
    }
   ],
   "source": [
    "print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "023e24eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.multi_hand_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c7a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0200c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
